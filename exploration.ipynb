{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-01T08:30:32.771435Z",
     "start_time": "2024-03-01T08:30:30.579465Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# This must be first\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\".env\")\n",
    "\n",
    "import os\n",
    "import string\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from core.utils.misc import seed_everything\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-01T08:32:12.392628Z",
     "start_time": "2024-03-01T08:32:12.310109Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'LLAMA_DIR'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmisc\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m limit_gpus\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodels\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mllm_loading\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m load_model_and_tokenizer, load_tokenizer\n\u001B[1;32m      4\u001B[0m limit_gpus(\u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m2\u001B[39m))\n\u001B[1;32m      6\u001B[0m \u001B[38;5;66;03m# model_type, model_variant = \"gpt-2\", \"1.5B\"\u001B[39;00m\n",
      "File \u001B[0;32m/workspace/icl_task_vectors/core/models/llm_loading.py:141\u001B[0m\n\u001B[1;32m    128\u001B[0m     model \u001B[38;5;241m=\u001B[39m load_model(model_type, model_variant, load_to_cpu\u001B[38;5;241m=\u001B[39mload_to_cpu)\n\u001B[1;32m    130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m model, tokenizer\n\u001B[1;32m    133\u001B[0m MODEL_PATHS \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m    134\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpythia\u001B[39m\u001B[38;5;124m\"\u001B[39m: {\n\u001B[1;32m    135\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m1.4B\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEleutherAI/pythia-1.4b\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    136\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m2.8B\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEleutherAI/pythia-2.8b\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    137\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m6.9B\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEleutherAI/pythia-6.9b\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    138\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m12B\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEleutherAI/pythia-12b\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    139\u001B[0m     },\n\u001B[1;32m    140\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mllama\u001B[39m\u001B[38;5;124m\"\u001B[39m: {\n\u001B[0;32m--> 141\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m7B\u001B[39m\u001B[38;5;124m\"\u001B[39m: llama_local_path(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhuggingface\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m7B\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m    142\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m13B\u001B[39m\u001B[38;5;124m\"\u001B[39m: llama_local_path(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhuggingface\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m13B\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m    143\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m30B\u001B[39m\u001B[38;5;124m\"\u001B[39m: llama_local_path(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhuggingface\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m30B\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m    144\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m65B\u001B[39m\u001B[38;5;124m\"\u001B[39m: llama_local_path(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhuggingface\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m65B\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m    145\u001B[0m     },\n\u001B[1;32m    146\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfalcon\u001B[39m\u001B[38;5;124m\"\u001B[39m: {\n\u001B[1;32m    147\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m7B\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtiiuae/falcon-7b\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    148\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m40B\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtiiuae/falcon-40b\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    149\u001B[0m     },\n\u001B[1;32m    150\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgpt-j\u001B[39m\u001B[38;5;124m\"\u001B[39m: {\n\u001B[1;32m    151\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m6B\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEleutherAI/gpt-j-6B\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    152\u001B[0m     },\n\u001B[1;32m    153\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgpt-2\u001B[39m\u001B[38;5;124m\"\u001B[39m: {\n\u001B[1;32m    154\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m0.35B\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgpt2-medium\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    155\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m0.77B\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgpt2-large\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    156\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m1.5B\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgpt2-xl\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    157\u001B[0m     },\n\u001B[1;32m    158\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmpt\u001B[39m\u001B[38;5;124m\"\u001B[39m: {\n\u001B[1;32m    159\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m7B\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmosaicml/mpt-7b\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    160\u001B[0m     },\n\u001B[1;32m    161\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgpt-neox\u001B[39m\u001B[38;5;124m\"\u001B[39m: {\n\u001B[1;32m    162\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m20B\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEleutherAI/gpt-neox-20b\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    163\u001B[0m     },\n\u001B[1;32m    164\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstarcoder\u001B[39m\u001B[38;5;124m\"\u001B[39m: {\n\u001B[1;32m    165\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mregular\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbigcode/starcoder\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    166\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mplus\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbigcode/starcoderplus\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    167\u001B[0m     },\n\u001B[1;32m    168\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcerebras-gpt\u001B[39m\u001B[38;5;124m\"\u001B[39m: {\n\u001B[1;32m    169\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m6.7B\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcerebras/Cerebras-GPT-6.7B\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    170\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m13B\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcerebras/Cerebras-GPT-13B\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    171\u001B[0m     },\n\u001B[1;32m    172\u001B[0m }\n",
      "File \u001B[0;32m/workspace/icl_task_vectors/core/models/llm_loading.py:37\u001B[0m, in \u001B[0;36mllama_local_path\u001B[0;34m(variant, size)\u001B[0m\n\u001B[1;32m     36\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mllama_local_path\u001B[39m(variant: LlamaVariant, size: LlamaSize) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mstr\u001B[39m:\n\u001B[0;32m---> 37\u001B[0m     llama_dir \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39menviron[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLLAMA_DIR\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m     38\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mllama_dir\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mvariant\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00msize\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n",
      "File \u001B[0;32m<frozen os>:679\u001B[0m, in \u001B[0;36m__getitem__\u001B[0;34m(self, key)\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 'LLAMA_DIR'"
     ]
    }
   ],
   "source": [
    "from core.utils.misc import limit_gpus\n",
    "from core.models.llm_loading import load_model_and_tokenizer, load_tokenizer\n",
    "\n",
    "limit_gpus(range(0, 2))\n",
    "\n",
    "# model_type, model_variant = \"gpt-2\", \"1.5B\"\n",
    "model_type, model_variant = \"llama\", \"7B\"\n",
    "# model_type, model_variant = \"gpt-j\", \"6B\"\n",
    "# model_type, model_variant = \"pythia\", \"2.8B\"\n",
    "# model_type, model_variant = \"pythia\", \"6.9B\"\n",
    "# model_type, model_variant = \"falcon\", \"7B\"\n",
    "# model_type, model_variant = \"mpt\", \"7B\"\n",
    "\n",
    "model, tokenizer = load_model_and_tokenizer(model_type, model_variant)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In Context Learning Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Experiment\n",
    "\n",
    "from core.task_vectors import run_icl, run_task_vector\n",
    "from core.data.task_helpers import get_task_by_name\n",
    "from core.analysis.evaluation import calculate_accuracy, calculate_accuracy_on_datasets, print_evaluation_summary\n",
    "\n",
    "seed_everything(41)\n",
    "\n",
    "# task_name = \"knowledge_country_capital\"\n",
    "# task_name = \"knowledge_person_language\"\n",
    "# task_name = \"knowledge_location_continent\"\n",
    "# task_name = \"knowledge_location_religion\"\n",
    "\n",
    "# task_name = \"algorithmic_prev_letter\"  # 0.57,0.40\n",
    "# task_name = \"algorithmic_next_letter\"  # 0.91, 0.94\n",
    "# task_name = \"algorithmic_list_first\"  # 1.00, 0.99\n",
    "# task_name = \"algorithmic_list_last\"  # 0.97, 0.86\n",
    "# task_name = \"algorithmic_to_upper\"  # 1.00, 0.96\n",
    "# task_name = \"algorithmic_to_lower\"  # 1.00, 0.88\n",
    "\n",
    "task_name = \"translation_fr_en\"\n",
    "# task_name = \"translation_es_en\"\n",
    "# task_name = \"translation_it_en\" \n",
    "# task_name = \"translation_en_fr\"\n",
    "# task_name = \"translation_en_es\"\n",
    "# task_name = \"translation_en_it\"\n",
    "\n",
    "# task_name = \"linguistic_present_simple_gerund\"  # 0.96, 0.80\n",
    "# task_name = \"linguistic_present_simple_past_simple\"  # 0.95, 0.94\n",
    "# task_name = \"linguistic_present_simple_past_perfect\"  # 0.79, 0.61\n",
    "# task_name = \"linguistic_plural_singular\"  # 0.90, 0.81\n",
    "# task_name = \"linguistic_antonyms\"  # 0.90, 0.88\n",
    "\n",
    "# task_name = \"sentiment\"\n",
    "\n",
    "num_examples = 5\n",
    "\n",
    "task = get_task_by_name(tokenizer, task_name)\n",
    "\n",
    "test_datasets = task.create_datasets(num_datasets=100, num_examples=num_examples)\n",
    "dev_datasets = task.create_datasets(num_datasets=50, num_examples=num_examples)\n",
    "\n",
    "icl_predictions = run_icl(model, tokenizer, task, test_datasets)\n",
    "print_evaluation_summary(task, icl_predictions, test_datasets)\n",
    "\n",
    "tv_predictions, tv_dev_accuracy_by_layer, task_hiddens = run_task_vector(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    task,\n",
    "    test_datasets,\n",
    "    dev_datasets,\n",
    "    multi_context=False\n",
    ")\n",
    "print_evaluation_summary(task, tv_predictions, test_datasets)\n",
    "# print(tv_dev_accuracy_by_layer)\n",
    "\n",
    "# icl_accuracy = calculate_accuracy_on_datasets(icl_predictions, test_datasets)\n",
    "# tv_accuracy = calculate_accuracy_on_datasets(tv_predictions, test_datasets)\n",
    "# print(f\"ICL accuracy: {icl_accuracy:.2f}\")\n",
    "# print(f\"TV accuracy: {tv_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overriding Experiment\n",
    "\n",
    "from typing import Any\n",
    "from core.task_vectors import run_icl, run_overriding_task_vector\n",
    "from core.data.task_helpers import get_task_by_name\n",
    "from core.analysis.evaluation import calculate_accuracy\n",
    "from core.data.tasks.task import Task\n",
    "from scripts.experiments.overriding import OVERRIDING_TASK_PAIRS\n",
    "\n",
    "def is_valid_input(task: Task, inp: Any) -> bool:\n",
    "    try:\n",
    "        task.calc_output(inp)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "seed_everything(41)\n",
    "\n",
    "\n",
    "task_name, overriding_task_name = OVERRIDING_TASK_PAIRS[3]\n",
    "\n",
    "num_examples = 4\n",
    "\n",
    "task = get_task_by_name(tokenizer, task_name)\n",
    "overriding_task = get_task_by_name(tokenizer, overriding_task_name)\n",
    "\n",
    "test_datasets = task.create_datasets(num_datasets=1000, num_examples=num_examples)\n",
    "overriding_datasets = overriding_task.create_datasets(num_datasets=100, num_examples=num_examples)\n",
    "\n",
    "# filter only test_datasets that are valid inputs for the overriding task\n",
    "test_datasets = [dataset for dataset in test_datasets if is_valid_input(overriding_task, dataset.test_input)]\n",
    "test_datasets = test_datasets[:len(overriding_datasets)]\n",
    "\n",
    "assert len(test_datasets) == len(overriding_datasets)\n",
    "\n",
    "icl_predictions = run_icl(model, tokenizer, task, test_datasets)\n",
    "tv_predictions, tv_dev_accuracy_by_layer, task_hiddens = run_overriding_task_vector(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    task,\n",
    "    test_datasets,\n",
    "    overriding_datasets,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "expected_outputs_original = [dataset.test_output for dataset in test_datasets]\n",
    "expected_outputs_patched = [overriding_task.calc_output(dataset.test_input) for dataset in test_datasets]\n",
    "\n",
    "icl_accuracy_original = calculate_accuracy(task,icl_predictions, expected_outputs_original)\n",
    "icl_accuracy_patched = calculate_accuracy(task,icl_predictions, expected_outputs_patched)\n",
    "\n",
    "tv_accuracy_original = calculate_accuracy(task,tv_predictions, expected_outputs_original)\n",
    "tv_accuracy_patched = calculate_accuracy(task,tv_predictions, expected_outputs_patched)\n",
    "\n",
    "print(f\"ICL accuracy original: {icl_accuracy_original:.2f}\")\n",
    "print(f\"ICL accuracy patched: {icl_accuracy_patched:.2f}\")\n",
    "print(f\"TV accuracy original: {tv_accuracy_original:.2f}\")\n",
    "print(f\"TV accuracy patched: {tv_accuracy_patched:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top tokens\n",
    "\n",
    "from core.analysis.utils import logits_top_tokens, tokens_ranks\n",
    "from core.models.utils.inference import hidden_to_logits\n",
    "from itertools import chain\n",
    "\n",
    "tv_ordered_tokens_by_layer = {}\n",
    "\n",
    "for layer_num in tv_dev_accuracy_by_layer.keys():\n",
    "    task_hidden = task_hiddens.mean(axis=0)[layer_num]\n",
    "    logits = hidden_to_logits(model, task_hidden)\n",
    "    tv_ordered_tokens_by_layer[layer_num] = logits_top_tokens(logits, tokenizer, k=500)\n",
    "    print(\"Top tokens for layer\", layer_num, \":\", tv_ordered_tokens_by_layer[layer_num][:12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if input+task=output\n",
    "\n",
    "from core.models.utils.llm_layers import get_lm_head, get_lm_pipeline\n",
    "from core.models.utils.inference import hidden_to_logits, logits_to_tokens\n",
    "\n",
    "# Find the layer that has the highest accuracy\n",
    "layer_num = max(tv_dev_accuracy_by_layer, key=tv_dev_accuracy_by_layer.get) + 3\n",
    "\n",
    "task_hidden = task_hiddens.mean(axis=0)[layer_num]\n",
    "\n",
    "embeddings = get_lm_head(model).weight.float().cpu()\n",
    "\n",
    "inputs = [dataset.test_input.strip() for dataset in test_datasets]\n",
    "\n",
    "inputs_token_ids = tokenizer(inputs, add_special_tokens=False).input_ids\n",
    "\n",
    "inputs_token_ids = [x[0] for x in inputs_token_ids if len(x) == 1]\n",
    "\n",
    "input_token_embeddings = embeddings[inputs_token_ids].cpu()\n",
    "\n",
    "# normalize embeddings and task_hidden\n",
    "input_token_embeddings = input_token_embeddings / input_token_embeddings.norm(dim=-1, keepdim=True)\n",
    "task_hidden = task_hidden / task_hidden.norm(dim=-1, keepdim=True)\n",
    "\n",
    "input_plus_task_embeddings = input_token_embeddings + task_hidden * 1.0\n",
    "\n",
    "logits = hidden_to_logits(model, input_plus_task_embeddings)\n",
    "# logits = embeddings @ input_plus_task_embeddings.T\n",
    "\n",
    "ignore_ids=inputs_token_ids\n",
    "# ignore_ids=None\n",
    "\n",
    "outputs = logits_to_tokens(logits, tokenizer, ignore_ids=ignore_ids)\n",
    "\n",
    "list(zip(inputs, outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.models.utils.inference import batch_generate, tokenize_prompts\n",
    "\n",
    "from transformers import TextGenerationPipeline\n",
    "\n",
    "prompt_examples = [\n",
    "    \"Canada -> Ottawa\",\n",
    "    # \"Australia -> Canberra\",\n",
    "    \"France -> Paris\",\n",
    "    \"Germany -> Berlin\",\n",
    "    # \"Australia -> Sydney\",\n",
    "    \"Switzerland ->\",\n",
    "    # \"India -> Mumbai\",\n",
    "    # \"China -> Shanghai\",\n",
    "    # \"Australia ->\"\n",
    "]\n",
    "\n",
    "prompt = \"\\n\".join(prompt_examples)\n",
    "\n",
    "pipeline = TextGenerationPipeline(model, tokenizer)\n",
    "\n",
    "completion = pipeline(prompt, max_new_tokens=2, num_return_sequences=1, do_sample=False)\n",
    "\n",
    "print(completion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
